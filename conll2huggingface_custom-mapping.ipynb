{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conll_to_json(input_file, output_file, class_mapping_file, custom_mapping):\n",
    "    data = []\n",
    "    current_sentence = {\"id\": \"0\", \"tokens\": [], \"ner_tags\": []}\n",
    "    sentence_id = 0\n",
    "    tag_counter = Counter()\n",
    "\n",
    "    # Invert the custom mapping for easier lookup\n",
    "    tag_dict = {v: k for k, v in custom_mapping.items()}\n",
    "\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('-DOCSTART-') or line == '':\n",
    "                if current_sentence[\"tokens\"]:\n",
    "                    data.append(current_sentence)\n",
    "                    sentence_id += 1\n",
    "                    current_sentence = {\"id\": str(sentence_id), \"tokens\": [], \"ner_tags\": []}\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 4:\n",
    "                    token, _, _, ner_tag = parts[:4]\n",
    "                    current_sentence[\"tokens\"].append(token)\n",
    "                    if ner_tag in tag_dict:\n",
    "                        current_sentence[\"ner_tags\"].append(tag_dict[ner_tag])\n",
    "                        tag_counter[ner_tag] += 1\n",
    "                    else:\n",
    "                        print(f\"Warning: Tag '{ner_tag}' not found in mapping. Using 0 (O) instead.\")\n",
    "                        current_sentence[\"ner_tags\"].append(0)\n",
    "                        tag_counter['O'] += 1\n",
    "\n",
    "    if current_sentence[\"tokens\"]:\n",
    "        data.append(current_sentence)\n",
    "\n",
    "    # Write to JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for item in data:\n",
    "            json.dump(item, f, ensure_ascii=False)\n",
    "            f.write('\\n')\n",
    "\n",
    "    # Write class mapping to a separate file\n",
    "    with open(class_mapping_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(\"tag_mapping = {\\n\")\n",
    "        for idx, tag in sorted(custom_mapping.items()):\n",
    "            f.write(f\"    {idx}: '{tag}',\\n\")\n",
    "        f.write(\"}\\n\")\n",
    "\n",
    "    print(f\"Processed {len(data)} sentences.\")\n",
    "    print(f\"Found {len(custom_mapping)} unique NER tags: {', '.join(custom_mapping.values())}\")\n",
    "    print(f\"Tag counts: {dict(tag_counter)}\")\n",
    "    print(\"Tag Mapping:\")\n",
    "    for idx, tag in sorted(custom_mapping.items()):\n",
    "        print(f\"    {idx}: '{tag}',\")\n",
    "    print(f\"Data saved to {output_file}\")\n",
    "    print(f\"Class mapping saved to {class_mapping_file}\")\n",
    "\n",
    "# Custom mapping\n",
    "custom_map = {\n",
    "    0: 'O',\n",
    "    1: 'B-Address',\n",
    "    2: 'I-Address',\n",
    "    3: 'B-Authority',\n",
    "    4: 'I-Authority',\n",
    "    5: 'B-Birth_Place',\n",
    "    6: 'I-Birth_Place',\n",
    "    7: 'B-Class',\n",
    "    8: 'I-Class',\n",
    "    9: 'B-Country',\n",
    "    10: 'I-Country',\n",
    "    11: 'B-DD',\n",
    "    12: 'I-DD',\n",
    "    13: 'B-DL_Class',\n",
    "    14: 'I-DL_Class',\n",
    "    15: 'B-Document_Number',\n",
    "    16: 'I-Document_Number',\n",
    "    17: 'B-Endorsement',\n",
    "    18: 'I-Endorsement',\n",
    "    19: 'B-Eyes',\n",
    "    20: 'I-Eyes',\n",
    "    21: 'B-First_Name',\n",
    "    22: 'I-First_Name',\n",
    "    23: 'B-Hair',\n",
    "    24: 'I-Hair',\n",
    "    25: 'B-Height',\n",
    "    26: 'I-Height',\n",
    "    27: 'B-Issuance_Number',\n",
    "    28: 'I-Issuance_Number',\n",
    "    29: 'B-Last_Name',\n",
    "    30: 'I-Last_Name',\n",
    "    31: 'B-License_Number',\n",
    "    32: 'I-License_Number',\n",
    "    33: 'B-License_Type',\n",
    "    34: 'I-License_Type',\n",
    "    35: 'B-Other',\n",
    "    36: 'I-Other',\n",
    "    37: 'B-Restrictions',\n",
    "    38: 'I-Restrictions',\n",
    "    39: 'B-Sex',\n",
    "    40: 'I-Sex',\n",
    "    41: 'B-State',\n",
    "    42: 'I-State',\n",
    "    43: 'B-Weight',\n",
    "    44: 'I-Weight',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 181 sentences.\n",
      "Found 45 unique NER tags: O, B-Address, I-Address, B-Authority, I-Authority, B-Birth_Place, I-Birth_Place, B-Class, I-Class, B-Country, I-Country, B-DD, I-DD, B-DL_Class, I-DL_Class, B-Document_Number, I-Document_Number, B-Endorsement, I-Endorsement, B-Eyes, I-Eyes, B-First_Name, I-First_Name, B-Hair, I-Hair, B-Height, I-Height, B-Issuance_Number, I-Issuance_Number, B-Last_Name, I-Last_Name, B-License_Number, I-License_Number, B-License_Type, I-License_Type, B-Other, I-Other, B-Restrictions, I-Restrictions, B-Sex, I-Sex, B-State, I-State, B-Weight, I-Weight\n",
      "Tag counts: {'O': 8375, 'B-State': 159, 'B-License_Number': 180, 'B-Endorsement': 104, 'B-Class': 113, 'B-Restrictions': 95, 'B-Sex': 132, 'B-Height': 131, 'I-Height': 277, 'B-Weight': 76, 'B-Eyes': 122, 'B-Last_Name': 184, 'B-First_Name': 184, 'B-Address': 208, 'I-Address': 1048, 'B-Document_Number': 58, 'B-Other': 64, 'B-Hair': 40, 'B-DD': 85, 'I-DD': 79, 'B-Country': 110, 'I-License_Number': 212, 'I-First_Name': 110, 'I-Last_Name': 21, 'I-Restrictions': 8, 'I-Endorsement': 10, 'I-Eyes': 10, 'I-Document_Number': 19, 'I-State': 28, 'I-Other': 20, 'I-Weight': 43, 'B-License_Type': 10, 'I-Hair': 2, 'I-Sex': 2, 'I-License_Type': 2, 'B-Birth_Place': 36, 'I-Birth_Place': 17, 'B-Authority': 37, 'B-Issuance_Number': 11, 'B-DL_Class': 35, 'I-DL_Class': 179, 'I-Issuance_Number': 1, 'I-Authority': 34, 'I-Country': 4, 'I-Class': 3}\n",
      "Tag Mapping:\n",
      "    0: 'O',\n",
      "    1: 'B-Address',\n",
      "    2: 'I-Address',\n",
      "    3: 'B-Authority',\n",
      "    4: 'I-Authority',\n",
      "    5: 'B-Birth_Place',\n",
      "    6: 'I-Birth_Place',\n",
      "    7: 'B-Class',\n",
      "    8: 'I-Class',\n",
      "    9: 'B-Country',\n",
      "    10: 'I-Country',\n",
      "    11: 'B-DD',\n",
      "    12: 'I-DD',\n",
      "    13: 'B-DL_Class',\n",
      "    14: 'I-DL_Class',\n",
      "    15: 'B-Document_Number',\n",
      "    16: 'I-Document_Number',\n",
      "    17: 'B-Endorsement',\n",
      "    18: 'I-Endorsement',\n",
      "    19: 'B-Eyes',\n",
      "    20: 'I-Eyes',\n",
      "    21: 'B-First_Name',\n",
      "    22: 'I-First_Name',\n",
      "    23: 'B-Hair',\n",
      "    24: 'I-Hair',\n",
      "    25: 'B-Height',\n",
      "    26: 'I-Height',\n",
      "    27: 'B-Issuance_Number',\n",
      "    28: 'I-Issuance_Number',\n",
      "    29: 'B-Last_Name',\n",
      "    30: 'I-Last_Name',\n",
      "    31: 'B-License_Number',\n",
      "    32: 'I-License_Number',\n",
      "    33: 'B-License_Type',\n",
      "    34: 'I-License_Type',\n",
      "    35: 'B-Other',\n",
      "    36: 'I-Other',\n",
      "    37: 'B-Restrictions',\n",
      "    38: 'I-Restrictions',\n",
      "    39: 'B-Sex',\n",
      "    40: 'I-Sex',\n",
      "    41: 'B-State',\n",
      "    42: 'I-State',\n",
      "    43: 'B-Weight',\n",
      "    44: 'I-Weight',\n",
      "Data saved to dataset_custom.json\n",
      "Class mapping saved to tag_mapping_custom.txt\n"
     ]
    }
   ],
   "source": [
    "# Usage\n",
    "conll_to_json(r'c:\\Users\\Sakib Ahmed\\Desktop\\dev_combined.conll', 'dataset_custom.json', 'tag_mapping_custom.txt', custom_mapping=custom_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
